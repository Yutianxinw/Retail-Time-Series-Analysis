{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":18599,"databundleVersionId":1236839,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T01:38:30.605239Z","iopub.execute_input":"2025-05-04T01:38:30.605397Z","iopub.status.idle":"2025-05-04T01:38:32.713664Z","shell.execute_reply.started":"2025-05-04T01:38:30.605382Z","shell.execute_reply":"2025-05-04T01:38:32.713002Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/m5-forecasting-accuracy/calendar.csv\n/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\n/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\n/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\n/kaggle/input/m5-forecasting-accuracy/sales_train_evaluation.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nsales = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")\nsales_data = sales.iloc[:, 6:].T  # Shape: (days, items) → (1913, 30490)\nsales_data.columns = sales['id'].values\n\n# === Load calendar.csv ===\ncalendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\n\n# === Select calendar columns used in training ===\ncalendar_cols = [\n    'wday', 'month', 'year',\n    'event_name_1', 'event_name_2', 'event_type_1',\n    'snap_CA', 'snap_TX', 'snap_WI'\n]\n\n# Prepare full calendar_feats first (used for training)\ncalendar_train = calendar.iloc[:1913][calendar_cols].copy()\ncalendar_train = calendar_train.fillna(\"none\")\ncalendar_feats = pd.get_dummies(calendar_train, columns=['event_name_1', 'event_name_2', 'event_type_1'])\n\n\n# ✅ Save calendar feature columns for future alignment (important for validation/eval)\nwith open(\"calendar_columns.pkl\", \"wb\") as f:\n    pickle.dump(calendar_feats.columns.tolist(), f)\n    \ncombined = pd.concat([sales_data.reset_index(drop=True), calendar_feats], axis=1)\n\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(combined)\n\n\nimport numpy as np\n# === Define sequence length ===\ninput_window = 28  # number of past days used as input\nnum_items = 30490  # number of items (sales columns only)\ntotal_days = scaled_data.shape[0]  # total time steps available\n\n# === Generate training sequences ===\nX_train, y_train = [], []\n\nfor i in range(input_window, total_days):\n    input_seq = scaled_data[i - input_window:i]  # shape: (28, features)\n    target = scaled_data[i][:num_items]          # shape: (30490,), only sales part\n\n    X_train.append(input_seq)\n    y_train.append(target)\n\nX_train = np.array(X_train, dtype=np.float32)\ny_train = np.array(y_train, dtype=np.float32)\n\nprint(f\"✅ X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:54:00.182578Z","iopub.execute_input":"2025-05-03T23:54:00.183045Z","iopub.status.idle":"2025-05-03T23:54:12.189607Z","shell.execute_reply.started":"2025-05-03T23:54:00.183022Z","shell.execute_reply":"2025-05-03T23:54:12.188911Z"}},"outputs":[{"name":"stdout","text":"✅ X_train shape: (1885, 28, 30537), y_train shape: (1885, 30490)\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# === Extract next 28 days: day 1914 to 1941 (for validation) or 1942–1969 (for evaluation) ===\ncalendar_future = calendar.iloc[1913:1941][calendar_cols].copy()\n\n# === Fill missing values and one-hot encode event-related categorical features ===\ncalendar_future = calendar_future.fillna(\"none\")\ncalendar_future = pd.get_dummies(calendar_future, columns=['event_name_1', 'event_name_2', 'event_type_1'])\n\n# === Ensure column alignment with training ===\ncalendar_future = calendar_future.reindex(columns=calendar_feats.columns, fill_value=0)\n\n# === Convert to float32 NumPy array ===\ncalendar_next_28 = calendar_future.values.astype(np.float32)  # shape: (28, calendar_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:54:14.855727Z","iopub.execute_input":"2025-05-03T23:54:14.856281Z","iopub.status.idle":"2025-05-03T23:54:14.866865Z","shell.execute_reply.started":"2025-05-03T23:54:14.856248Z","shell.execute_reply":"2025-05-03T23:54:14.865993Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\n\n# === Define Model Architecture ===\ndef build_global_lstm_model(input_timesteps, num_features, num_items, dropout_rate=0.2):\n    model = Sequential()\n\n    # LSTM layers\n    model.add(LSTM(units=64, return_sequences=True, input_shape=(input_timesteps, num_features)))\n    model.add(Dropout(dropout_rate))\n\n    model.add(LSTM(units=128, return_sequences=True))\n    model.add(Dropout(dropout_rate))\n\n    model.add(LSTM(units=128))  # Last layer: return_sequences=False\n    model.add(Dropout(dropout_rate))\n\n    # Output layer (no activation)\n    model.add(Dense(units=num_items))\n\n    # Optimizer\n    optimizer = Adam(learning_rate=0.001)\n\n    model.compile(optimizer=optimizer, loss='huber')\n\n    # Learning rate scheduler\n    lr_callback = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=3,\n        min_lr=1e-6,\n        verbose=1\n    )\n\n    return model, lr_callback\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:54:18.452540Z","iopub.execute_input":"2025-05-03T23:54:18.452817Z","iopub.status.idle":"2025-05-03T23:54:18.459046Z","shell.execute_reply.started":"2025-05-03T23:54:18.452798Z","shell.execute_reply":"2025-05-03T23:54:18.458121Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# === Build and Train Model ===\nmodel, lr_callback = build_global_lstm_model(\n    input_timesteps=28,\n    num_features=X_train.shape[2],\n    num_items=30490\n)\n\nmodel.fit(\n    X_train, y_train,\n    epochs=20,\n    batch_size=32,\n    validation_split=0.1,\n    callbacks=[lr_callback],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:54:25.341416Z","iopub.execute_input":"2025-05-03T23:54:25.341679Z","iopub.status.idle":"2025-05-03T23:56:06.391728Z","shell.execute_reply.started":"2025-05-03T23:54:25.341660Z","shell.execute_reply":"2025-05-03T23:56:06.390978Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - loss: 0.0087 - val_loss: 0.0101 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0068 - val_loss: 0.0095 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.0065 - val_loss: 0.0094 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0063 - val_loss: 0.0094 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0062 - val_loss: 0.0093 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0061 - val_loss: 0.0093 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0061 - val_loss: 0.0093 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0060\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0060 - val_loss: 0.0094 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0059 - val_loss: 0.0094 - learning_rate: 5.0000e-04\nEpoch 10/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0059 - val_loss: 0.0093 - learning_rate: 5.0000e-04\nEpoch 11/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0059\nEpoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.0059 - val_loss: 0.0093 - learning_rate: 5.0000e-04\nEpoch 12/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0059 - val_loss: 0.0093 - learning_rate: 2.5000e-04\nEpoch 13/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0059 - val_loss: 0.0093 - learning_rate: 2.5000e-04\nEpoch 14/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0058 - val_loss: 0.0092 - learning_rate: 2.5000e-04\nEpoch 15/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0058 - val_loss: 0.0092 - learning_rate: 2.5000e-04\nEpoch 16/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0058 - val_loss: 0.0092 - learning_rate: 2.5000e-04\nEpoch 17/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0058\nEpoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0058 - val_loss: 0.0092 - learning_rate: 2.5000e-04\nEpoch 18/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0057 - val_loss: 0.0092 - learning_rate: 1.2500e-04\nEpoch 19/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.0057 - val_loss: 0.0092 - learning_rate: 1.2500e-04\nEpoch 20/20\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0057\nEpoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0057 - val_loss: 0.0092 - learning_rate: 1.2500e-04\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b94d3113ed0>"},"metadata":{}}],"execution_count":65},{"cell_type":"code","source":"# === Load calendar columns for alignment ===\nwith open(\"calendar_columns.pkl\", \"rb\") as f:\n    calendar_columns = pickle.load(f)\n\ncalendar = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\ncalendar_cols = ['wday', 'month', 'year', 'event_name_1', 'event_name_2', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI']\n\n# === Prepare input and calendar features for validation ===\ncalendar_future_val = calendar.iloc[1913:1941][calendar_cols].copy()\ncalendar_future_val = calendar_future_val.fillna(\"none\")\ncalendar_future_val = pd.get_dummies(calendar_future_val, columns=['event_name_1', 'event_name_2', 'event_type_1'])\ncalendar_future_val = calendar_future_val.reindex(columns=calendar_columns, fill_value=0)\ncalendar_next_28_val = calendar_future_val.values.astype(np.float32)\n\nlast_28_days_input_val = scaled_data[-28:, :].astype(np.float32)\n\n# === Forecasting Function ===\ndef forecast_28_days(model, input_sequence, calendar_future, num_items):\n    window = input_sequence.shape[0]\n    input_data = input_sequence.copy()\n    predictions = []\n\n    for day in range(28):\n        x_input = input_data[-window:].reshape(1, window, -1)\n        y_pred = model.predict(x_input, verbose=0)\n\n        # Inspect prediction values\n        print(\"Prediction summary:\", y_pred.min(), y_pred.max(), y_pred.mean())\n\n        # Reconstruct full row for inverse transform (pad calendar zeros for inverse)\n        full_pred_row = np.concatenate([y_pred[0], np.zeros(calendar_future.shape[1])]).reshape(1, -1)\n        y_pred_original = scaler.inverse_transform(full_pred_row)[:, :num_items]\n\n        # Add prediction (scaled again) + real calendar to next input\n        y_pred_scaled = scaler.transform(full_pred_row)[:, :num_items]\n        next_input_row = np.concatenate([y_pred_scaled[0], calendar_future[day]])\n        input_data = np.vstack([input_data, next_input_row])\n\n        predictions.append(y_pred_original)\n\n    return np.vstack(predictions)\n\n# === Forecast Validation Period ===\nforecast_val = forecast_28_days(\n    model=model,\n    input_sequence=last_28_days_input_val,\n    calendar_future=calendar_next_28_val,\n    num_items=30490\n)\nforecast_val = np.clip(forecast_val, 0, None).T\n\n# === Build submission DataFrame for validation ===\nsales = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\")\nids_val = sales['id'].values\nsubmission_val_df = pd.DataFrame(forecast_val, columns=[f\"F{i}\" for i in range(1, 29)])\nsubmission_val_df.insert(0, \"id\", ids_val)\nsubmission_val_df.to_csv(\"submission_val.csv\", index=False)\nprint(\"✅ submission_val.csv saved successfully!\")\n\n# === Prepare calendar for evaluation period ===\ncalendar_future_eval = calendar.iloc[1941:1969][calendar_cols].copy()\ncalendar_future_eval = calendar_future_eval.fillna(\"none\")\ncalendar_future_eval = pd.get_dummies(calendar_future_eval, columns=['event_name_1', 'event_name_2', 'event_type_1'])\ncalendar_future_eval = calendar_future_eval.reindex(columns=calendar_columns, fill_value=0)\ncalendar_next_28_eval = calendar_future_eval.values.astype(np.float32)\n\nlast_28_days_input_eval = scaled_data[-28:, :].astype(np.float32)\n\n# === Forecast Evaluation Period ===\nforecast_eval = forecast_28_days(model, last_28_days_input_eval, calendar_next_28_eval, num_items=30490)\nforecast_eval = np.clip(forecast_eval, 0, None).T\n\n# === Build submission DataFrame for evaluation ===\nids_eval = [i.replace(\"validation\", \"evaluation\") for i in sales[\"id\"].values]\nsubmission_eval_df = pd.DataFrame(forecast_eval, columns=[f\"F{i}\" for i in range(1, 29)])\nsubmission_eval_df.insert(0, \"id\", ids_eval)\nsubmission_eval_df.to_csv(\"submission_eval.csv\", index=False)\nprint(\"✅ submission_eval.csv saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:57:31.762191Z","iopub.execute_input":"2025-05-03T23:57:31.762860Z","iopub.status.idle":"2025-05-03T23:57:40.805240Z","shell.execute_reply.started":"2025-05-03T23:57:31.762835Z","shell.execute_reply":"2025-05-03T23:57:40.804446Z"}},"outputs":[{"name":"stdout","text":"Prediction summary: -0.029571217 0.5268835 0.08579148\nPrediction summary: -0.029586967 0.51839876 0.08463582\nPrediction summary: -0.029538155 0.5313871 0.086427465\nPrediction summary: -0.028945543 0.5371337 0.08721996\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.028069634 0.54042274 0.08768477\nPrediction summary: -0.027162064 0.5418157 0.08791434\nPrediction summary: -0.025391791 0.5419805 0.087837316\nPrediction summary: -0.02267912 0.54171294 0.0875806\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.021080088 0.5378747 0.08683897\nPrediction summary: -0.020914115 0.52920604 0.08555251\nPrediction summary: -0.020282678 0.5212192 0.084387906\nPrediction summary: -0.019309524 0.5157156 0.0835061\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.01993031 0.51149243 0.082765244\nPrediction summary: -0.020544775 0.50594974 0.08178883\nPrediction summary: -0.021614384 0.49653023 0.08037489\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.02355538 0.48795193 0.079228245\nPrediction summary: -0.025222953 0.48285574 0.07852501\nPrediction summary: -0.026561975 0.47982004 0.07812129\nPrediction summary: -0.027631603 0.47819632 0.07790544\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.02846295 0.47729903 0.07776228\nPrediction summary: -0.029160481 0.4764979 0.07755292\nPrediction summary: -0.029647972 0.4770078 0.07733361\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.030553788 0.4777442 0.07714031\nPrediction summary: -0.031727903 0.4779258 0.077028915\nPrediction summary: -0.032986775 0.47748664 0.076990105\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.034724228 0.4770871 0.07701031\nPrediction summary: -0.038722567 0.47857904 0.07718556\nPrediction summary: -0.052333966 0.4838448 0.07734371\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ submission_val.csv saved successfully!\nPrediction summary: -0.029571217 0.5268835 0.08579148\nPrediction summary: -0.029591337 0.5185751 0.08465937\nPrediction summary: -0.029538043 0.53164697 0.086460404\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.028936557 0.53739566 0.08725099\nPrediction summary: -0.028051492 0.540672 0.08771219\nPrediction summary: -0.027135588 0.5420549 0.08793875\nPrediction summary: -0.025355201 0.54225516 0.08786473\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.022634156 0.5417217 0.087571405\nPrediction summary: -0.021039587 0.53761584 0.08679632\nPrediction summary: -0.020897582 0.5287458 0.08548717\nPrediction summary: -0.020290822 0.52110696 0.08437223\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.01931322 0.5155927 0.08348831\nPrediction summary: -0.019946173 0.51149297 0.08276402\nPrediction summary: -0.02055278 0.50596416 0.081787795\nPrediction summary: -0.021604251 0.49673444 0.08039749\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.023541138 0.4881546 0.07924891\nPrediction summary: -0.025213115 0.48305774 0.078546636\nPrediction summary: -0.026553154 0.4800517 0.07814614\nPrediction summary: -0.027624901 0.47853684 0.077943094\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.028458174 0.477625 0.07779651\nPrediction summary: -0.029158544 0.47687328 0.07759282\nPrediction summary: -0.0296475 0.47734186 0.07736515\nPrediction summary: -0.030554742 0.47812936 0.07717847\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.031733606 0.47833642 0.07706851\nPrediction summary: -0.032998234 0.47799408 0.07704148\nPrediction summary: -0.03474366 0.47751305 0.077047326\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Prediction summary: -0.038756013 0.47896683 0.077215284\nPrediction summary: -0.05239045 0.48423424 0.07736974\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"✅ submission_eval.csv saved successfully!\n","output_type":"stream"}],"execution_count":67},{"cell_type":"code","source":"import pandas as pd\n\n# === Load validation and evaluation prediction files ===\nsubmission_val = pd.read_csv(\"submission_val.csv\")\nsubmission_eval = pd.read_csv(\"submission_eval.csv\")\n\n# === Combine both parts ===\nsubmission_all = pd.concat([submission_val, submission_eval], axis=0).reset_index(drop=True)\n\n# === Load sample_submission to match required order ===\nsample = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")\n\n# === Align predictions to sample_submission id order ===\nfinal_submission = sample[['id']].merge(submission_all, on='id', how='left')\n\n# === Validate submission ===\nnum_duplicates = final_submission['id'].duplicated().sum()\nnum_missing = final_submission.isnull().sum().sum()\n\nassert num_duplicates == 0, f\"❌ Found {num_duplicates} duplicate ID(s) in submission\"\nassert num_missing == 0, f\"❌ Found {num_missing} missing prediction(s) in submission\"\n\n# === Save final file ===\nfinal_submission.to_csv(\"final_submission.csv\", index=False)\nprint(f\"✅ Final submission saved: {len(final_submission)} rows → final_submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-03T23:57:48.026141Z","iopub.execute_input":"2025-05-03T23:57:48.026849Z","iopub.status.idle":"2025-05-03T23:57:51.074173Z","shell.execute_reply.started":"2025-05-03T23:57:48.026827Z","shell.execute_reply":"2025-05-03T23:57:51.073170Z"}},"outputs":[{"name":"stdout","text":"✅ Final submission saved: 60980 rows → final_submission.csv\n","output_type":"stream"}],"execution_count":68}]}